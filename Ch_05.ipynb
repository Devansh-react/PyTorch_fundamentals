{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDLBS9FoJbnGQjunr7H7k7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devansh-react/PyTorch_fundamentals/blob/main/Ch_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G4uOvsPpyg4w"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create a synthetic classification dataset using sklearn\n",
        "X, y = make_classification(\n",
        "    n_samples=10,       # Number of samples\n",
        "    n_features=2,       # Number of features\n",
        "    n_informative=2,    # Number of informative features\n",
        "    n_redundant=0,      # Number of redundant features\n",
        "    n_classes=2,        # Number of classes\n",
        "    random_state=42     # For reproducibility\n",
        ")"
      ],
      "metadata": {
        "id": "2H1IshiSy_mv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape,X,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAZ4oJDtzDmU",
        "outputId": "993bb51d-cea2-47af-de6c-99197f39c4fa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10, 2),\n",
              " array([[ 1.06833894, -0.97007347],\n",
              "        [-1.14021544, -0.83879234],\n",
              "        [-2.8953973 ,  1.97686236],\n",
              "        [-0.72063436, -0.96059253],\n",
              "        [-1.96287438, -0.99225135],\n",
              "        [-0.9382051 , -0.54304815],\n",
              "        [ 1.72725924, -1.18582677],\n",
              "        [ 1.77736657,  1.51157598],\n",
              "        [ 1.89969252,  0.83444483],\n",
              "        [-0.58723065, -1.97171753]]),\n",
              " array([1, 0, 0, 0, 0, 1, 1, 1, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.long)"
      ],
      "metadata": {
        "id": "jjIbD3_NzLHL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,feature,labels):\n",
        "    self.feature = feature\n",
        "    self.labels = labels\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return  self.feature.shape[0]\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.feature[index],self.labels[index]"
      ],
      "metadata": {
        "id": "ax0ZTa5uzQIv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(X,y)"
      ],
      "metadata": {
        "id": "Q03nDxO80ahH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset),dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNvjxOw21B1N",
        "outputId": "e5999e3e-1511-480e-9229-953fbfe5a909"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, (tensor([ 1.0683, -0.9701]), tensor(1)))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset,batch_size=2,shuffle=True)"
      ],
      "metadata": {
        "id": "jlP1ODt02HJq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_feature,batch_lable in dataloader:\n",
        "  print(batch_feature)\n",
        "  print(batch_lable)\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_B7PNRV2aMB",
        "outputId": "322521b2-57b0-4a09-cd5a-c2650f7bc9b9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.9382, -0.5430],\n",
            "        [-2.8954,  1.9769]])\n",
            "tensor([1, 0])\n",
            "--------------------------------------------------\n",
            "tensor([[-0.5872, -1.9717],\n",
            "        [ 1.7774,  1.5116]])\n",
            "tensor([0, 1])\n",
            "--------------------------------------------------\n",
            "tensor([[-1.1402, -0.8388],\n",
            "        [ 1.7273, -1.1858]])\n",
            "tensor([0, 1])\n",
            "--------------------------------------------------\n",
            "tensor([[ 1.0683, -0.9701],\n",
            "        [-1.9629, -0.9923]])\n",
            "tensor([1, 0])\n",
            "--------------------------------------------------\n",
            "tensor([[ 1.8997,  0.8344],\n",
            "        [-0.7206, -0.9606]])\n",
            "tensor([1, 0])\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Trainig model pipeline**"
      ],
      "metadata": {
        "id": "oIoFUkxDAVto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,feature,labels):\n",
        "    self.feature = feature\n",
        "    self.labels = labels\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return  self.feature.shape[0]\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.feature[index],self.labels[index]"
      ],
      "metadata": {
        "id": "GUlglJrjBoc5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
        "df.drop([\"Unnamed: 32\",\"id\"],axis=1,inplace=True)\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(df.iloc[:,1:],df.iloc[:,0],test_size=0.2)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "encoder = LabelEncoder()\n",
        "Y_train = encoder.fit_transform(Y_train)\n",
        "Y_test = encoder.transform(Y_test)\n",
        "X_train_tensor = torch.from_numpy(X_train).float()\n",
        "X_test_tensor = torch.from_numpy(X_test).float()\n",
        "Y_train_tensor = torch.from_numpy(Y_train).float()\n",
        "Y_test_tensor = torch.from_numpy(Y_test).float()\n",
        "X_train_tensor.shape,X_test_tensor.shape,Y_train_tensor.shape,Y_test_tensor.shape\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUDVdJ9HASUg",
        "outputId": "56176931-c6ef-4eb8-d215-c562a9fed852"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([455, 30]),\n",
              " torch.Size([114, 30]),\n",
              " torch.Size([455]),\n",
              " torch.Size([114]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Trainig_class(nn.Module):\n",
        "  def __init__(self,num_features):\n",
        "    super().__init__()\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Linear(num_features,1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self,X):\n",
        "    out = self.network(X)\n",
        "    return out\n",
        "\n",
        "#  paramneters\n",
        "learning_rate = 0.001;\n",
        "epochs = 25"
      ],
      "metadata": {
        "id": "zxK9EQEMAih0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(X_train_tensor,Y_train_tensor)\n",
        "test_dataset = CustomDataset(X_test_tensor,Y_test_tensor)"
      ],
      "metadata": {
        "id": "nLWgAdosA-NJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloder = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset,batch_size=32,shuffle=True)"
      ],
      "metadata": {
        "id": "4VFBLKQxBw8p"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fun = nn.BCELoss()"
      ],
      "metadata": {
        "id": "hx5BF47qCT9n"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model  = Trainig_class(X_train_tensor.shape[1])\n",
        "\n",
        "#optimiser\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  for batch_features , batch_labels in train_dataloder:\n",
        "\n",
        "    # forward-pass\n",
        "    y_pred = model(batch_features) # Pass features to the model\n",
        "    #  loss function\n",
        "    loss = loss_fun(y_pred,batch_labels.view(-1,1)) # Use labels for loss calculation\n",
        "\n",
        "    #clearing gradient\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # backward_propogation\n",
        "    loss.backward()\n",
        "\n",
        "    # parameter_update (using in-place operations)\n",
        "    optimizer.step()\n",
        "\n",
        "    # print loss in each epoch\n",
        "    print(f'Epoch: {epoch + 1}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc5c9Q0oBLfS",
        "outputId": "1fa2ad3e-7bb3-4d1c-b74d-ca85cd290e44"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.8332481980323792\n",
            "Epoch: 1, Loss: 0.7689734697341919\n",
            "Epoch: 1, Loss: 0.8905272483825684\n",
            "Epoch: 1, Loss: 0.7646952271461487\n",
            "Epoch: 1, Loss: 0.8160474896430969\n",
            "Epoch: 1, Loss: 0.8368940949440002\n",
            "Epoch: 1, Loss: 0.8075826168060303\n",
            "Epoch: 1, Loss: 0.7816641926765442\n",
            "Epoch: 1, Loss: 0.8987591862678528\n",
            "Epoch: 1, Loss: 0.8681702017784119\n",
            "Epoch: 1, Loss: 0.8116330504417419\n",
            "Epoch: 1, Loss: 0.8293501138687134\n",
            "Epoch: 1, Loss: 0.7759166955947876\n",
            "Epoch: 1, Loss: 0.8470827341079712\n",
            "Epoch: 1, Loss: 0.7564606070518494\n",
            "Epoch: 2, Loss: 0.7850606441497803\n",
            "Epoch: 2, Loss: 0.7861133813858032\n",
            "Epoch: 2, Loss: 0.7423028349876404\n",
            "Epoch: 2, Loss: 0.8014739155769348\n",
            "Epoch: 2, Loss: 0.7855833768844604\n",
            "Epoch: 2, Loss: 0.8257344365119934\n",
            "Epoch: 2, Loss: 0.7504908442497253\n",
            "Epoch: 2, Loss: 0.7931350469589233\n",
            "Epoch: 2, Loss: 0.8231688737869263\n",
            "Epoch: 2, Loss: 0.8098085522651672\n",
            "Epoch: 2, Loss: 0.7593505382537842\n",
            "Epoch: 2, Loss: 0.7563107013702393\n",
            "Epoch: 2, Loss: 0.8165281414985657\n",
            "Epoch: 2, Loss: 0.7811788320541382\n",
            "Epoch: 2, Loss: 0.6138860583305359\n",
            "Epoch: 3, Loss: 0.726921021938324\n",
            "Epoch: 3, Loss: 0.7532896399497986\n",
            "Epoch: 3, Loss: 0.796244740486145\n",
            "Epoch: 3, Loss: 0.7325581312179565\n",
            "Epoch: 3, Loss: 0.7241421937942505\n",
            "Epoch: 3, Loss: 0.767815113067627\n",
            "Epoch: 3, Loss: 0.7425236701965332\n",
            "Epoch: 3, Loss: 0.7530432939529419\n",
            "Epoch: 3, Loss: 0.7662057876586914\n",
            "Epoch: 3, Loss: 0.7816506624221802\n",
            "Epoch: 3, Loss: 0.713378369808197\n",
            "Epoch: 3, Loss: 0.7960346937179565\n",
            "Epoch: 3, Loss: 0.7325620055198669\n",
            "Epoch: 3, Loss: 0.7084306478500366\n",
            "Epoch: 3, Loss: 0.7231302261352539\n",
            "Epoch: 4, Loss: 0.7425278425216675\n",
            "Epoch: 4, Loss: 0.7325878143310547\n",
            "Epoch: 4, Loss: 0.7126713395118713\n",
            "Epoch: 4, Loss: 0.7001261711120605\n",
            "Epoch: 4, Loss: 0.7057945728302002\n",
            "Epoch: 4, Loss: 0.7026487588882446\n",
            "Epoch: 4, Loss: 0.7360064387321472\n",
            "Epoch: 4, Loss: 0.7256931066513062\n",
            "Epoch: 4, Loss: 0.6906983852386475\n",
            "Epoch: 4, Loss: 0.7037505507469177\n",
            "Epoch: 4, Loss: 0.7282059788703918\n",
            "Epoch: 4, Loss: 0.7232509851455688\n",
            "Epoch: 4, Loss: 0.7162469029426575\n",
            "Epoch: 4, Loss: 0.7350336313247681\n",
            "Epoch: 4, Loss: 0.6713348031044006\n",
            "Epoch: 5, Loss: 0.7440072894096375\n",
            "Epoch: 5, Loss: 0.6675121188163757\n",
            "Epoch: 5, Loss: 0.7112413048744202\n",
            "Epoch: 5, Loss: 0.7106475234031677\n",
            "Epoch: 5, Loss: 0.7499886751174927\n",
            "Epoch: 5, Loss: 0.6474263072013855\n",
            "Epoch: 5, Loss: 0.698556125164032\n",
            "Epoch: 5, Loss: 0.6667476296424866\n",
            "Epoch: 5, Loss: 0.6889452338218689\n",
            "Epoch: 5, Loss: 0.6887972354888916\n",
            "Epoch: 5, Loss: 0.7005661725997925\n",
            "Epoch: 5, Loss: 0.6174762845039368\n",
            "Epoch: 5, Loss: 0.6545439958572388\n",
            "Epoch: 5, Loss: 0.6669191122055054\n",
            "Epoch: 5, Loss: 0.7474877238273621\n",
            "Epoch: 6, Loss: 0.6230369210243225\n",
            "Epoch: 6, Loss: 0.7031255960464478\n",
            "Epoch: 6, Loss: 0.6707605123519897\n",
            "Epoch: 6, Loss: 0.6943101286888123\n",
            "Epoch: 6, Loss: 0.7356533408164978\n",
            "Epoch: 6, Loss: 0.6644155979156494\n",
            "Epoch: 6, Loss: 0.682494580745697\n",
            "Epoch: 6, Loss: 0.6576112508773804\n",
            "Epoch: 6, Loss: 0.6872044801712036\n",
            "Epoch: 6, Loss: 0.6171950697898865\n",
            "Epoch: 6, Loss: 0.607513964176178\n",
            "Epoch: 6, Loss: 0.5797175765037537\n",
            "Epoch: 6, Loss: 0.6736401319503784\n",
            "Epoch: 6, Loss: 0.6365509629249573\n",
            "Epoch: 6, Loss: 0.6876096129417419\n",
            "Epoch: 7, Loss: 0.6500355005264282\n",
            "Epoch: 7, Loss: 0.696848452091217\n",
            "Epoch: 7, Loss: 0.6454829573631287\n",
            "Epoch: 7, Loss: 0.620934784412384\n",
            "Epoch: 7, Loss: 0.6423091292381287\n",
            "Epoch: 7, Loss: 0.6423975229263306\n",
            "Epoch: 7, Loss: 0.5673591494560242\n",
            "Epoch: 7, Loss: 0.6535910367965698\n",
            "Epoch: 7, Loss: 0.6629255414009094\n",
            "Epoch: 7, Loss: 0.5886045098304749\n",
            "Epoch: 7, Loss: 0.6525532603263855\n",
            "Epoch: 7, Loss: 0.625893235206604\n",
            "Epoch: 7, Loss: 0.642690896987915\n",
            "Epoch: 7, Loss: 0.6199759244918823\n",
            "Epoch: 7, Loss: 0.5871949195861816\n",
            "Epoch: 8, Loss: 0.6342350244522095\n",
            "Epoch: 8, Loss: 0.609607458114624\n",
            "Epoch: 8, Loss: 0.682796835899353\n",
            "Epoch: 8, Loss: 0.6077582836151123\n",
            "Epoch: 8, Loss: 0.6097962260246277\n",
            "Epoch: 8, Loss: 0.6079737544059753\n",
            "Epoch: 8, Loss: 0.559788703918457\n",
            "Epoch: 8, Loss: 0.6446518898010254\n",
            "Epoch: 8, Loss: 0.5949493050575256\n",
            "Epoch: 8, Loss: 0.6064031720161438\n",
            "Epoch: 8, Loss: 0.622280478477478\n",
            "Epoch: 8, Loss: 0.5804475545883179\n",
            "Epoch: 8, Loss: 0.6190924644470215\n",
            "Epoch: 8, Loss: 0.6195895671844482\n",
            "Epoch: 8, Loss: 0.5643637776374817\n",
            "Epoch: 9, Loss: 0.6153830885887146\n",
            "Epoch: 9, Loss: 0.5830247402191162\n",
            "Epoch: 9, Loss: 0.5975896716117859\n",
            "Epoch: 9, Loss: 0.58765709400177\n",
            "Epoch: 9, Loss: 0.5694164037704468\n",
            "Epoch: 9, Loss: 0.6747298836708069\n",
            "Epoch: 9, Loss: 0.5989519953727722\n",
            "Epoch: 9, Loss: 0.5879458785057068\n",
            "Epoch: 9, Loss: 0.5318566560745239\n",
            "Epoch: 9, Loss: 0.6110610961914062\n",
            "Epoch: 9, Loss: 0.580843448638916\n",
            "Epoch: 9, Loss: 0.5879140496253967\n",
            "Epoch: 9, Loss: 0.6148316860198975\n",
            "Epoch: 9, Loss: 0.5841780304908752\n",
            "Epoch: 9, Loss: 0.4660370349884033\n",
            "Epoch: 10, Loss: 0.6157210469245911\n",
            "Epoch: 10, Loss: 0.5655641555786133\n",
            "Epoch: 10, Loss: 0.5944097638130188\n",
            "Epoch: 10, Loss: 0.5721097588539124\n",
            "Epoch: 10, Loss: 0.5650061368942261\n",
            "Epoch: 10, Loss: 0.5763038992881775\n",
            "Epoch: 10, Loss: 0.5934363007545471\n",
            "Epoch: 10, Loss: 0.5673668384552002\n",
            "Epoch: 10, Loss: 0.5420141816139221\n",
            "Epoch: 10, Loss: 0.5492315292358398\n",
            "Epoch: 10, Loss: 0.5066757202148438\n",
            "Epoch: 10, Loss: 0.603853702545166\n",
            "Epoch: 10, Loss: 0.564221203327179\n",
            "Epoch: 10, Loss: 0.6053648591041565\n",
            "Epoch: 10, Loss: 0.6119651794433594\n",
            "Epoch: 11, Loss: 0.5137072205543518\n",
            "Epoch: 11, Loss: 0.5632789731025696\n",
            "Epoch: 11, Loss: 0.5582723617553711\n",
            "Epoch: 11, Loss: 0.6079979538917542\n",
            "Epoch: 11, Loss: 0.5623437762260437\n",
            "Epoch: 11, Loss: 0.5371630191802979\n",
            "Epoch: 11, Loss: 0.5514418482780457\n",
            "Epoch: 11, Loss: 0.5639688372612\n",
            "Epoch: 11, Loss: 0.5313559770584106\n",
            "Epoch: 11, Loss: 0.5816328525543213\n",
            "Epoch: 11, Loss: 0.5220670700073242\n",
            "Epoch: 11, Loss: 0.5614696741104126\n",
            "Epoch: 11, Loss: 0.5420969128608704\n",
            "Epoch: 11, Loss: 0.5687280297279358\n",
            "Epoch: 11, Loss: 0.6469798684120178\n",
            "Epoch: 12, Loss: 0.5141171216964722\n",
            "Epoch: 12, Loss: 0.5583926439285278\n",
            "Epoch: 12, Loss: 0.5829840898513794\n",
            "Epoch: 12, Loss: 0.5391514897346497\n",
            "Epoch: 12, Loss: 0.5677871704101562\n",
            "Epoch: 12, Loss: 0.5691629648208618\n",
            "Epoch: 12, Loss: 0.5152173042297363\n",
            "Epoch: 12, Loss: 0.5110224485397339\n",
            "Epoch: 12, Loss: 0.48566126823425293\n",
            "Epoch: 12, Loss: 0.5100741386413574\n",
            "Epoch: 12, Loss: 0.5744718313217163\n",
            "Epoch: 12, Loss: 0.5652067065238953\n",
            "Epoch: 12, Loss: 0.546606183052063\n",
            "Epoch: 12, Loss: 0.5032848715782166\n",
            "Epoch: 12, Loss: 0.6173688173294067\n",
            "Epoch: 13, Loss: 0.5542040467262268\n",
            "Epoch: 13, Loss: 0.4667218029499054\n",
            "Epoch: 13, Loss: 0.49990275502204895\n",
            "Epoch: 13, Loss: 0.5474286675453186\n",
            "Epoch: 13, Loss: 0.49913865327835083\n",
            "Epoch: 13, Loss: 0.5639165639877319\n",
            "Epoch: 13, Loss: 0.47600874304771423\n",
            "Epoch: 13, Loss: 0.5703861117362976\n",
            "Epoch: 13, Loss: 0.5483957529067993\n",
            "Epoch: 13, Loss: 0.5282233357429504\n",
            "Epoch: 13, Loss: 0.5339667201042175\n",
            "Epoch: 13, Loss: 0.5214457511901855\n",
            "Epoch: 13, Loss: 0.514844536781311\n",
            "Epoch: 13, Loss: 0.5480775237083435\n",
            "Epoch: 13, Loss: 0.4247172474861145\n",
            "Epoch: 14, Loss: 0.5338655710220337\n",
            "Epoch: 14, Loss: 0.4882737398147583\n",
            "Epoch: 14, Loss: 0.4838864207267761\n",
            "Epoch: 14, Loss: 0.5048858523368835\n",
            "Epoch: 14, Loss: 0.5846289396286011\n",
            "Epoch: 14, Loss: 0.5010294318199158\n",
            "Epoch: 14, Loss: 0.5651246905326843\n",
            "Epoch: 14, Loss: 0.5890981554985046\n",
            "Epoch: 14, Loss: 0.4526291489601135\n",
            "Epoch: 14, Loss: 0.4980918765068054\n",
            "Epoch: 14, Loss: 0.47880375385284424\n",
            "Epoch: 14, Loss: 0.4690760374069214\n",
            "Epoch: 14, Loss: 0.5107250213623047\n",
            "Epoch: 14, Loss: 0.5036500692367554\n",
            "Epoch: 14, Loss: 0.4849998652935028\n",
            "Epoch: 15, Loss: 0.5045896172523499\n",
            "Epoch: 15, Loss: 0.5196225047111511\n",
            "Epoch: 15, Loss: 0.5241739749908447\n",
            "Epoch: 15, Loss: 0.5286193490028381\n",
            "Epoch: 15, Loss: 0.47415870428085327\n",
            "Epoch: 15, Loss: 0.512787938117981\n",
            "Epoch: 15, Loss: 0.47584956884384155\n",
            "Epoch: 15, Loss: 0.46172618865966797\n",
            "Epoch: 15, Loss: 0.4319254457950592\n",
            "Epoch: 15, Loss: 0.5657473206520081\n",
            "Epoch: 15, Loss: 0.48732563853263855\n",
            "Epoch: 15, Loss: 0.5100204348564148\n",
            "Epoch: 15, Loss: 0.45364290475845337\n",
            "Epoch: 15, Loss: 0.5286542177200317\n",
            "Epoch: 15, Loss: 0.484198659658432\n",
            "Epoch: 16, Loss: 0.5018266439437866\n",
            "Epoch: 16, Loss: 0.5135870575904846\n",
            "Epoch: 16, Loss: 0.42272526025772095\n",
            "Epoch: 16, Loss: 0.523186981678009\n",
            "Epoch: 16, Loss: 0.4978890120983124\n",
            "Epoch: 16, Loss: 0.5055536031723022\n",
            "Epoch: 16, Loss: 0.4854842722415924\n",
            "Epoch: 16, Loss: 0.5786643028259277\n",
            "Epoch: 16, Loss: 0.4863888621330261\n",
            "Epoch: 16, Loss: 0.48233434557914734\n",
            "Epoch: 16, Loss: 0.44334882497787476\n",
            "Epoch: 16, Loss: 0.48157259821891785\n",
            "Epoch: 16, Loss: 0.5008420944213867\n",
            "Epoch: 16, Loss: 0.4024783968925476\n",
            "Epoch: 16, Loss: 0.4106680452823639\n",
            "Epoch: 17, Loss: 0.4535346031188965\n",
            "Epoch: 17, Loss: 0.49178916215896606\n",
            "Epoch: 17, Loss: 0.4688583016395569\n",
            "Epoch: 17, Loss: 0.5053423643112183\n",
            "Epoch: 17, Loss: 0.48636704683303833\n",
            "Epoch: 17, Loss: 0.45939838886260986\n",
            "Epoch: 17, Loss: 0.5179178714752197\n",
            "Epoch: 17, Loss: 0.490364670753479\n",
            "Epoch: 17, Loss: 0.463280588388443\n",
            "Epoch: 17, Loss: 0.480763703584671\n",
            "Epoch: 17, Loss: 0.4205530881881714\n",
            "Epoch: 17, Loss: 0.47407403588294983\n",
            "Epoch: 17, Loss: 0.4333556294441223\n",
            "Epoch: 17, Loss: 0.5104919075965881\n",
            "Epoch: 17, Loss: 0.4579557478427887\n",
            "Epoch: 18, Loss: 0.48727741837501526\n",
            "Epoch: 18, Loss: 0.4816722869873047\n",
            "Epoch: 18, Loss: 0.41743388772010803\n",
            "Epoch: 18, Loss: 0.3944264054298401\n",
            "Epoch: 18, Loss: 0.4334482252597809\n",
            "Epoch: 18, Loss: 0.4124593734741211\n",
            "Epoch: 18, Loss: 0.4740367829799652\n",
            "Epoch: 18, Loss: 0.486581951379776\n",
            "Epoch: 18, Loss: 0.5218555927276611\n",
            "Epoch: 18, Loss: 0.5108290910720825\n",
            "Epoch: 18, Loss: 0.4799857437610626\n",
            "Epoch: 18, Loss: 0.4200822114944458\n",
            "Epoch: 18, Loss: 0.49187925457954407\n",
            "Epoch: 18, Loss: 0.49221324920654297\n",
            "Epoch: 18, Loss: 0.4719512164592743\n",
            "Epoch: 19, Loss: 0.4584767818450928\n",
            "Epoch: 19, Loss: 0.43658536672592163\n",
            "Epoch: 19, Loss: 0.4394299387931824\n",
            "Epoch: 19, Loss: 0.5041121244430542\n",
            "Epoch: 19, Loss: 0.3799561858177185\n",
            "Epoch: 19, Loss: 0.45057761669158936\n",
            "Epoch: 19, Loss: 0.49900904297828674\n",
            "Epoch: 19, Loss: 0.44598475098609924\n",
            "Epoch: 19, Loss: 0.5295594334602356\n",
            "Epoch: 19, Loss: 0.3975887894630432\n",
            "Epoch: 19, Loss: 0.5028572678565979\n",
            "Epoch: 19, Loss: 0.42487195134162903\n",
            "Epoch: 19, Loss: 0.42259952425956726\n",
            "Epoch: 19, Loss: 0.5001060366630554\n",
            "Epoch: 19, Loss: 0.350177526473999\n",
            "Epoch: 20, Loss: 0.4405636787414551\n",
            "Epoch: 20, Loss: 0.5254330039024353\n",
            "Epoch: 20, Loss: 0.43660876154899597\n",
            "Epoch: 20, Loss: 0.4138270616531372\n",
            "Epoch: 20, Loss: 0.465749591588974\n",
            "Epoch: 20, Loss: 0.4313690662384033\n",
            "Epoch: 20, Loss: 0.36444780230522156\n",
            "Epoch: 20, Loss: 0.38830697536468506\n",
            "Epoch: 20, Loss: 0.4336918294429779\n",
            "Epoch: 20, Loss: 0.513718843460083\n",
            "Epoch: 20, Loss: 0.45133116841316223\n",
            "Epoch: 20, Loss: 0.4954453706741333\n",
            "Epoch: 20, Loss: 0.41867706179618835\n",
            "Epoch: 20, Loss: 0.4818575382232666\n",
            "Epoch: 20, Loss: 0.34880417585372925\n",
            "Epoch: 21, Loss: 0.37221580743789673\n",
            "Epoch: 21, Loss: 0.398004412651062\n",
            "Epoch: 21, Loss: 0.4721822738647461\n",
            "Epoch: 21, Loss: 0.4633634090423584\n",
            "Epoch: 21, Loss: 0.40376102924346924\n",
            "Epoch: 21, Loss: 0.467148095369339\n",
            "Epoch: 21, Loss: 0.42751023173332214\n",
            "Epoch: 21, Loss: 0.4358421266078949\n",
            "Epoch: 21, Loss: 0.5018815398216248\n",
            "Epoch: 21, Loss: 0.340234637260437\n",
            "Epoch: 21, Loss: 0.3708287477493286\n",
            "Epoch: 21, Loss: 0.45295193791389465\n",
            "Epoch: 21, Loss: 0.4676801562309265\n",
            "Epoch: 21, Loss: 0.5213721990585327\n",
            "Epoch: 21, Loss: 0.5345828533172607\n",
            "Epoch: 22, Loss: 0.3970831036567688\n",
            "Epoch: 22, Loss: 0.42256200313568115\n",
            "Epoch: 22, Loss: 0.4641406238079071\n",
            "Epoch: 22, Loss: 0.4195585250854492\n",
            "Epoch: 22, Loss: 0.4295901656150818\n",
            "Epoch: 22, Loss: 0.4121628701686859\n",
            "Epoch: 22, Loss: 0.4019514322280884\n",
            "Epoch: 22, Loss: 0.38868483901023865\n",
            "Epoch: 22, Loss: 0.4376535713672638\n",
            "Epoch: 22, Loss: 0.41140174865722656\n",
            "Epoch: 22, Loss: 0.46926191449165344\n",
            "Epoch: 22, Loss: 0.44055765867233276\n",
            "Epoch: 22, Loss: 0.4911835193634033\n",
            "Epoch: 22, Loss: 0.3958570063114166\n",
            "Epoch: 22, Loss: 0.5243736505508423\n",
            "Epoch: 23, Loss: 0.43329575657844543\n",
            "Epoch: 23, Loss: 0.4954438805580139\n",
            "Epoch: 23, Loss: 0.4391275644302368\n",
            "Epoch: 23, Loss: 0.3684113621711731\n",
            "Epoch: 23, Loss: 0.37963709235191345\n",
            "Epoch: 23, Loss: 0.43622127175331116\n",
            "Epoch: 23, Loss: 0.37315958738327026\n",
            "Epoch: 23, Loss: 0.49386778473854065\n",
            "Epoch: 23, Loss: 0.36819586157798767\n",
            "Epoch: 23, Loss: 0.4526080787181854\n",
            "Epoch: 23, Loss: 0.42577582597732544\n",
            "Epoch: 23, Loss: 0.40158170461654663\n",
            "Epoch: 23, Loss: 0.40527215600013733\n",
            "Epoch: 23, Loss: 0.4176296889781952\n",
            "Epoch: 23, Loss: 0.4347436726093292\n",
            "Epoch: 24, Loss: 0.39295876026153564\n",
            "Epoch: 24, Loss: 0.4511638879776001\n",
            "Epoch: 24, Loss: 0.4266548752784729\n",
            "Epoch: 24, Loss: 0.39820635318756104\n",
            "Epoch: 24, Loss: 0.45001211762428284\n",
            "Epoch: 24, Loss: 0.45409467816352844\n",
            "Epoch: 24, Loss: 0.37127700448036194\n",
            "Epoch: 24, Loss: 0.37570422887802124\n",
            "Epoch: 24, Loss: 0.4216257631778717\n",
            "Epoch: 24, Loss: 0.46582579612731934\n",
            "Epoch: 24, Loss: 0.42432329058647156\n",
            "Epoch: 24, Loss: 0.35776591300964355\n",
            "Epoch: 24, Loss: 0.40522468090057373\n",
            "Epoch: 24, Loss: 0.4014766216278076\n",
            "Epoch: 24, Loss: 0.39357778429985046\n",
            "Epoch: 25, Loss: 0.3946343958377838\n",
            "Epoch: 25, Loss: 0.39607447385787964\n",
            "Epoch: 25, Loss: 0.3562963306903839\n",
            "Epoch: 25, Loss: 0.3909261226654053\n",
            "Epoch: 25, Loss: 0.49010536074638367\n",
            "Epoch: 25, Loss: 0.37033551931381226\n",
            "Epoch: 25, Loss: 0.40174567699432373\n",
            "Epoch: 25, Loss: 0.4157814085483551\n",
            "Epoch: 25, Loss: 0.39922377467155457\n",
            "Epoch: 25, Loss: 0.39884454011917114\n",
            "Epoch: 25, Loss: 0.4005403518676758\n",
            "Epoch: 25, Loss: 0.44046229124069214\n",
            "Epoch: 25, Loss: 0.436461865901947\n",
            "Epoch: 25, Loss: 0.41918307542800903\n",
            "Epoch: 25, Loss: 0.33064332604408264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval() # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad(): # Disable gradient calculation during evaluation\n",
        "    for batch_features, batch_labels in test_dataloader:\n",
        "        outputs = model(batch_features)\n",
        "        predicted = (outputs > 0.5).float() # Apply threshold to get binary predictions\n",
        "        total += batch_labels.size(0)\n",
        "        correct += (predicted.squeeze() == batch_labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the model on the test data: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K37LlMpBDjgB",
        "outputId": "0ac54003-d6c9-4279-8a1f-ec4db7212ab8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the test data: 93.86%\n"
          ]
        }
      ]
    }
  ]
}